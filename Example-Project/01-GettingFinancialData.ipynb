{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting The Data\n",
    "Brian Bahmanyar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** NOTE:** This notebook will not run without implementing your own get_token function to return a Quandl API token\n",
    "* **just use the data from ./data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Quandl](https://www.quandl.com) provides free daily financial data which will be used in the analyses to come. They also provide a free, but somewhat lackluster Python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import Quandl\n",
    "from my_token import get_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> get_token is a function that returns my Quandl API token, replace with your information as necessary. Or just use the data below, provided in /data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function written to serve as a wrapper around Quandl's Python API and provide some needed functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_adj_close(token, tickers, start, end=\"\", ratios=[], log_transforms=[]):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        tickers (list): collection of ticker symbols for which to collect adj. close \n",
    "                daily prices for\n",
    "        start (string, format: 2013-01-01): start date for which to collect prices after\n",
    "        end (string, format: 2013-01-01): optional end date, today if not specified\n",
    "        ratios (list): collection of tuples of tickers from 'tickers' list to calculate \n",
    "                price ratios for (the stock with larger mean is numerator)\n",
    "        log_transforms (list): collection of tickers from 'tickers' to include additional \n",
    "                natural log transformed copies\n",
    "    \n",
    "    Returns (dataframe): all adj. close prices, ratios, and log transforms specified\n",
    "    \"\"\" \n",
    "    result = {}\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            result[ticker] = Quandl.get('WIKI/'+ticker, trim_start=start, trim_end=end, authtoken=token)['Adj. Close']\n",
    "        except DatasetNotFound:\n",
    "            print('ERROR:')\n",
    "            print(ticker, 'is not a vaild ticker')\n",
    "\n",
    "    for ratio in ratios:\n",
    "        try:\n",
    "            ticker1, ticker2 = ratio\n",
    "            if result[ticker1].mean() > result[ticker2].mean():\n",
    "                result[ticker1+'/'+ticker2] = result[ticker1]/result[ticker2]\n",
    "            else:\n",
    "                result[ticker2+'/'+ticker1] = result[ticker2]/result[ticker1]\n",
    "        except KeyError:\n",
    "            print('ERROR:')\n",
    "            print(ticker1, 'or', ticker2, 'are not in the list of specified tickers')\n",
    "    \n",
    "    for log_transform in log_transforms:\n",
    "        try:\n",
    "            result['ln('+log_transform+')'] = np.log(result[log_transform])\n",
    "        except KeyError:\n",
    "            print('ERROR:')\n",
    "            print(log_transform, 'is not in the list of specified tickers')\n",
    "    \n",
    "    return pd.DataFrame(result).dropna() # drop na here because of differences in lenght of history for stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A copy of this function is placed into api_wrapper.py for use in other notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to Get the Data We Need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tech_bundle = get_adj_close(get_token(),\n",
    "                            ['FB', 'AMZN', 'AAPL'], \n",
    "                            start='2013-01-01', \n",
    "                            ratios=[('FB','AMZN'), ('FB','AAPL'), ('AMZN','AAPL')],\n",
    "                            log_transforms=['FB', 'AMZN', 'AAPL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_bundle = get_adj_close(get_token(),\n",
    "                            ['VZ', 'T', 'KO', 'PEP', 'XOM', 'CVX'], \n",
    "                            start='1990-01-01', \n",
    "                            ratios=[('VZ','T'), ('KO','PEP'), ('XOM','CVX')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tech_bundle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs_bundle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tech_bundle.to_csv('data/tech_bundle.csv')\n",
    "# pairs_bundle.to_csv('data/pairs_bundle.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>@import \"http://fonts.googleapis.com/css?family=Lato|Source+Code+Pro|Montserrat:400,700\";@font-face{font-family:\"Computer Modern\";src:url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf')}.rendered_html h1,h2,h3,h4,h5,h6,p{font-family:'Computer Modern'}p,ul{font-family:'Computer Modern'}div#notebook-container{-webkit-box-shadow:none;box-shadow:none}h1{font-size:70pt}h2{font-size:50pt}h3{font-size:40pt}h4{font-size:35pt}h5{font-size:30pt}h6{font-size:25pt}.rendered_html p{font-size:11pt;line-height:14pt}.CodeMirror pre{font-family:'Source Code Pro', monospace;font-size:09pt}div.input_area{border:none;background:#f5f5f5}ul{font-size:10.5pt;font-family:'Computer Modern'}ol{font-size:11pt;font-family:'Computer Modern'}.output_png img{display:block;margin-left:auto;margin-right:auto}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<style>@import \"http://fonts.googleapis.com/css?family=Lato|Source+Code+Pro|Montserrat:400,700\";@font-face{font-family:\"Computer Modern\";src:url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf')}.rendered_html h1,h2,h3,h4,h5,h6,p{font-family:'Computer Modern'}p,ul{font-family:'Computer Modern'}div#notebook-container{-webkit-box-shadow:none;box-shadow:none}h1{font-size:70pt}h2{font-size:50pt}h3{font-size:40pt}h4{font-size:35pt}h5{font-size:30pt}h6{font-size:25pt}.rendered_html p{font-size:11pt;line-height:14pt}.CodeMirror pre{font-family:'Source Code Pro', monospace;font-size:09pt}div.input_area{border:none;background:#f5f5f5}ul{font-size:10.5pt;font-family:'Computer Modern'}ol{font-size:11pt;font-family:'Computer Modern'}.output_png img{display:block;margin-left:auto;margin-right:auto}</style>\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
